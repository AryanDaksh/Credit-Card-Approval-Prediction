{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 >Credit Card Approval Prediction Using Sklearn</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\..File Path../application_record.csv\", encoding = 'utf-8') \n",
    "record = pd.read_csv(r\"C:\\Users\\..File Path../credit_record.csv\", encoding = 'utf-8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all users' account open month.\n",
    "begin_month=pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "begin_month=begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "new_data=pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['dep_value'] = None\n",
    "record['dep_value'][record['STATUS'] =='2']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='3']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='4']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='5']='Yes' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpunt=record.groupby('ID').count()\n",
    "cpunt['dep_value'][cpunt['dep_value'] > 0]='Yes' \n",
    "cpunt['dep_value'][cpunt['dep_value'] == 0]='No' \n",
    "cpunt = cpunt[['dep_value']]\n",
    "new_data=pd.merge(new_data,cpunt,how='inner',on='ID')\n",
    "new_data['target']=new_data['dep_value']\n",
    "new_data.loc[new_data['target']=='Yes','target']=1\n",
    "new_data.loc[new_data['target']=='No','target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpunt['dep_value'].value_counts())\n",
    "cpunt['dep_value'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ rename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.rename(columns={'CODE_GENDER':'Gender','FLAG_OWN_CAR':'Car','FLAG_OWN_REALTY':'Reality',\n",
    "                         'CNT_CHILDREN':'ChldNo','AMT_INCOME_TOTAL':'inc',\n",
    "                         'NAME_EDUCATION_TYPE':'edutp','NAME_FAMILY_STATUS':'famtp',\n",
    "                        'NAME_HOUSING_TYPE':'houtp','FLAG_EMAIL':'email',\n",
    "                         'NAME_INCOME_TYPE':'inctp','FLAG_WORK_PHONE':'wkphone',\n",
    "                         'FLAG_PHONE':'phone','CNT_FAM_MEMBERS':'famsize',\n",
    "                        'OCCUPATION_TYPE':'occyp'\n",
    "                        },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna()\n",
    "new_data = new_data.mask(new_data == 'NULL').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=pd.DataFrame(new_data.columns,columns=['variable'])\n",
    "ivtable['IV']=None\n",
    "namelist = ['FLAG_MOBIL','begin_month','dep_value','target','ID']\n",
    "\n",
    "for i in namelist:\n",
    "    ivtable.drop(ivtable[ivtable['variable'] == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information value\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    \n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "    print('This variable\\'s IV is:',iv)\n",
    "    print(df[feature].value_counts())\n",
    "    return iv, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dummy(df, feature,rank=0):\n",
    "    pos = pd.get_dummies(df[feature], prefix=feature)\n",
    "    mode = df[feature].value_counts().index[rank]\n",
    "    biggest = feature + '_' + str(mode)\n",
    "    pos.drop([biggest],axis=1,inplace=True)\n",
    "    df.drop([feature],axis=1,inplace=True)\n",
    "    df=df.join(pos)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(df, col, binsnum, labels, qcut = False):\n",
    "    if qcut:\n",
    "        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n",
    "    else:\n",
    "        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n",
    "        \n",
    "    localdf = pd.DataFrame(localdf)\n",
    "    name = 'gp' + '_' + col\n",
    "    localdf[name] = localdf[col]\n",
    "    df = df.join(localdf[name])\n",
    "    df[name] = df[name].astype(object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Gender'] = new_data['Gender'].replace(['F','M'],[0,1])\n",
    "print(new_data['Gender'].value_counts())\n",
    "iv, data = calc_iv(new_data,'Gender','target')\n",
    "ivtable.loc[ivtable['variable']=='Gender','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a car or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Car'] = new_data['Car'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Car'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Car','target')\n",
    "ivtable.loc[ivtable['variable']=='Car','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having house reality or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Reality'] = new_data['Reality'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Reality'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Reality','target')\n",
    "ivtable.loc[ivtable['variable']=='Reality','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['phone']=new_data['phone'].astype(str)\n",
    "print(new_data['phone'].value_counts(normalize=True,sort=False))\n",
    "new_data.drop(new_data[new_data['phone'] == 'nan' ].index, inplace=True)\n",
    "iv, data=calc_iv(new_data,'phone','target')\n",
    "ivtable.loc[ivtable['variable']=='phone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having an email or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['email'].value_counts(normalize=True,sort=False))\n",
    "new_data['email']=new_data['email'].astype(str)\n",
    "iv, data=calc_iv(new_data,'email','target')\n",
    "ivtable.loc[ivtable['variable']=='email','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a Work Phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['wkphone']=new_data['wkphone'].astype(str)\n",
    "iv, data = calc_iv(new_data,'wkphone','target')\n",
    "new_data.drop(new_data[new_data['wkphone'] == 'nan' ].index, inplace=True)\n",
    "ivtable.loc[ivtable['variable']=='wkphone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables\n",
    "\n",
    "#### Children Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['ChldNo'] >= 2,'ChldNo']='2More'\n",
    "print(new_data['ChldNo'].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'ChldNo','target')\n",
    "ivtable.loc[ivtable['variable']=='ChldNo','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'ChldNo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['inc']=new_data['inc'].astype(object)\n",
    "new_data['inc'] = new_data['inc']/10000 \n",
    "print(new_data['inc'].value_counts(bins=10,sort=False))\n",
    "new_data['inc'].plot(kind='hist',bins=50,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'inc', 3, [\"low\",\"medium\", \"high\"], qcut = True)\n",
    "iv, data = calc_iv(new_data,'gp_inc','target')\n",
    "ivtable.loc[ivtable['variable']=='inc','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_inc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Age']=-(new_data['DAYS_BIRTH'])//365\t\n",
    "print(new_data['Age'].value_counts(bins=10,normalize=True,sort=False))\n",
    "new_data['Age'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'Age',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data = calc_iv(new_data,'gp_Age','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','IV'] = iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['worktm']=-(new_data['DAYS_EMPLOYED'])//365\t\n",
    "new_data[new_data['worktm']<0] = np.nan # replace by na\n",
    "new_data['DAYS_EMPLOYED']\n",
    "new_data['worktm'].fillna(new_data['worktm'].mean(),inplace=True) #replace na by mean\n",
    "new_data['worktm'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'worktm',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data=calc_iv(new_data,'gp_worktm','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_worktm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Famliy Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize']=new_data['famsize'].astype(int)\n",
    "new_data['famsizegp']=new_data['famsize']\n",
    "new_data['famsizegp']=new_data['famsizegp'].astype(object)\n",
    "new_data.loc[new_data['famsizegp']>=3,'famsizegp']='3more'\n",
    "iv, data=calc_iv(new_data,'famsizegp','target')\n",
    "ivtable.loc[ivtable['variable']=='famsize','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famsizegp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['inctp'].value_counts(sort=False))\n",
    "print(new_data['inctp'].value_counts(normalize=True,sort=False))\n",
    "new_data.loc[new_data['inctp']=='Pensioner','inctp']='State servant'\n",
    "new_data.loc[new_data['inctp']=='Student','inctp']='State servant'\n",
    "iv, data=calc_iv(new_data,'inctp','target')\n",
    "ivtable.loc[ivtable['variable']=='inctp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'inctp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[(new_data['occyp']=='Cleaning staff') | (new_data['occyp']=='Cooking staff') | (new_data['occyp']=='Drivers') | (new_data['occyp']=='Laborers') | (new_data['occyp']=='Low-skill Laborers') | (new_data['occyp']=='Security staff') | (new_data['occyp']=='Waiters/barmen staff'),'occyp']='Laborwk'\n",
    "new_data.loc[(new_data['occyp']=='Accountants') | (new_data['occyp']=='Core staff') | (new_data['occyp']=='HR staff') | (new_data['occyp']=='Medicine staff') | (new_data['occyp']=='Private service staff') | (new_data['occyp']=='Realty agents') | (new_data['occyp']=='Sales staff') | (new_data['occyp']=='Secretaries'),'occyp']='officewk'\n",
    "new_data.loc[(new_data['occyp']=='Managers') | (new_data['occyp']=='High skill tech staff') | (new_data['occyp']=='IT staff'),'occyp']='hightecwk'\n",
    "print(new_data['occyp'].value_counts())\n",
    "iv, data=calc_iv(new_data,'occyp','target')\n",
    "ivtable.loc[ivtable['variable']=='occyp','IV']=iv\n",
    "data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'occyp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### House Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'houtp','target')\n",
    "ivtable.loc[ivtable['variable']=='houtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'houtp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['edutp']=='Academic degree','edutp']='Higher education'\n",
    "iv, data=calc_iv(new_data,'edutp','target')\n",
    "ivtable.loc[ivtable['variable']=='edutp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'edutp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Marriage Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data['famtp'].value_counts(normalize=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'famtp','target')\n",
    "ivtable.loc[ivtable['variable']=='famtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famtp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=ivtable.sort_values(by='IV',ascending=False)\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','variable']='agegp'\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','variable']='worktmgp'\n",
    "ivtable.loc[ivtable['variable']=='inc','variable']='incgp'\n",
    "ivtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = new_data['target']\n",
    "X = new_data[['Gender','Reality','ChldNo_1', 'ChldNo_2More','wkphone',\n",
    "              'gp_Age_high', 'gp_Age_highest', 'gp_Age_low',\n",
    "       'gp_Age_lowest','gp_worktm_high', 'gp_worktm_highest',\n",
    "       'gp_worktm_low', 'gp_worktm_medium','occyp_hightecwk', \n",
    "              'occyp_officewk','famsizegp_1', 'famsizegp_3more',\n",
    "       'houtp_Co-op apartment', 'houtp_Municipal apartment',\n",
    "       'houtp_Office apartment', 'houtp_Rented apartment',\n",
    "       'houtp_With parents','edutp_Higher education',\n",
    "       'edutp_Incomplete higher', 'edutp_Lower secondary','famtp_Civil marriage',\n",
    "       'famtp_Separated','famtp_Single / not married','famtp_Widow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype('int')\n",
    "X_balance, Y_balance = SMOTE().fit_resample(X, Y)\n",
    "X_balance = pd.DataFrame(X_balance, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balance,Y_balance, \n",
    "                                                    stratify=Y_balance, test_size=0.3,\n",
    "                                                    random_state = 10086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Logistic Regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=12,\n",
    "                               min_samples_split=8,\n",
    "                               random_state=1024)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: CART')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest   \n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://d1rwhvwstyk9gu.cloudfront.net/2019/03/Random-Forest-Algorithm.jpg\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Random Forest</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=250,\n",
    "                              max_depth=12,\n",
    "                              min_samples_leaf=16\n",
    "                              )\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Ramdom Forests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://i.loli.net/2019/11/13/fryWG5al7OPHDiA.gif\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Support Vector Machine</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(C = 0.8,\n",
    "                kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numerical\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply to the 'wkphone' column\n",
    "X_train['wkphone'] = label_encoder.fit_transform(X_train['wkphone'])\n",
    "X_test['wkphone'] = label_encoder.transform(X_test['wkphone'])\n",
    "\n",
    "model = LGBMClassifier(num_leaves=31,\n",
    "                       max_depth=8, \n",
    "                       learning_rate=0.02,\n",
    "                       n_estimators=250,\n",
    "                       subsample=0.8,\n",
    "                       colsample_bytree=0.8\n",
    "                      )\n",
    "\n",
    "# Model training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Evaluating model performance\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "\n",
    "# Confusion matrix with optional labels\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_predict),\n",
    "                           index=['Actual Negative', 'Actual Positive'],\n",
    "                           columns=['Predicted Negative', 'Predicted Positive'])\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(classifer, x_train, point_size = 25):\n",
    "    '''plot feature importance'''\n",
    "    values = sorted(zip(x_train.columns, classifer.feature_importances_), key = lambda x: x[1] * -1)\n",
    "    imp = pd.DataFrame(values,columns = [\"Name\", \"Score\"])\n",
    "    imp.sort_values(by = 'Score',inplace = True)\n",
    "    sns.scatterplot(x = 'Score',y='Name', linewidth = 0,\n",
    "                data = imp,s = point_size, color='red').set(\n",
    "    xlabel='importance', \n",
    "    ylabel='features')\n",
    "    \n",
    "plot_importance(model, X_train,20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=12,\n",
    "                      n_estimators=250,\n",
    "                      min_child_weight=8, \n",
    "                      subsample=0.8, \n",
    "                      learning_rate =0.02,    \n",
    "                      seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model, X_train, 20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.2,\n",
    "                           od_type='Iter',\n",
    "                           verbose=25,\n",
    "                           depth=16,\n",
    "                           random_seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('CatBoost Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
